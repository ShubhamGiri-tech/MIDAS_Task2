{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "taken-johnson",
   "metadata": {},
   "source": [
    "Code for splitting the dataset into two sub folders namely train and val."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "manufactured-lexington",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying files: 2480 files [00:06, 376.05 files/s]\n"
     ]
    }
   ],
   "source": [
    "import splitfolders\n",
    "splitfolders.ratio(\"./trainCNN\", output=\"trainingdata\", seed=1337, ratio=(.8, .2), group_prefix=None) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "specific-relative",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elect-battlefield",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "promising-cherry",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.callbacks import ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "immune-driving",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "becoming-broadway",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(rescale=1./255,\n",
    "                                  shear_range=0.2,\n",
    "                                  zoom_range=0.2,\n",
    "                                  horizontal_flip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "killing-nature",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_datagen = ImageDataGenerator(rescale=1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "current-organ",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1984 images belonging to 62 classes.\n"
     ]
    }
   ],
   "source": [
    "training_set = train_datagen.flow_from_directory('./trainingdata/train',\n",
    "                                                 target_size=(64, 64),\n",
    "                                                 batch_size= 32,\n",
    "                                                 class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "transparent-strengthening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 496 images belonging to 62 classes.\n"
     ]
    }
   ],
   "source": [
    "val_set = val_datagen.flow_from_directory('./trainingdata/val',\n",
    "                                                        target_size = (64, 64),\n",
    "                                                        batch_size = 32,\n",
    "                                                        class_mode = 'categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "conservative-essence",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "silent-tobago",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the method for model\n",
    "#Step 1- Convolution\n",
    "classifier.add(Convolution2D(128, (3, 3), input_shape = (64, 64, 3), activation = 'relu'))\n",
    "classifier.add(Convolution2D(64, (3, 3), activation = 'relu'))\n",
    "\n",
    "#adding another layer\n",
    "classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "#Pooling it\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
    "\n",
    "#Adding another layer\n",
    "classifier.add(Convolution2D(32, (3, 3), activation = 'relu'))\n",
    "\n",
    "\n",
    "#Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "usual-multiple",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Step 3- Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Step 4- Full connection\n",
    "classifier.add(Dense(units = 128, activation = 'relu'))\n",
    "\n",
    "#For the output step\n",
    "classifier.add(Dense(units = 62, activation = 'softmax'))\n",
    "classifier.add(Dropout(0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "treated-taiwan",
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier.compile(optimizer = 'adam',loss = 'categorical_crossentropy', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "thick-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-20-a776bf97192a>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/36\n",
      "60/60 [==============================] - 145s 2s/step - loss: 4.2292 - accuracy: 0.0271 - val_loss: 3.9722 - val_accuracy: 0.0464\n",
      "Epoch 2/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 3.7489 - accuracy: 0.1047 - val_loss: 3.4246 - val_accuracy: 0.1653\n",
      "Epoch 3/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 3.0255 - accuracy: 0.2432 - val_loss: 2.8921 - val_accuracy: 0.2843\n",
      "Epoch 4/36\n",
      "60/60 [==============================] - 122s 2s/step - loss: 2.3968 - accuracy: 0.3979 - val_loss: 2.7607 - val_accuracy: 0.3286\n",
      "Epoch 5/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 1.9913 - accuracy: 0.5031 - val_loss: 2.3595 - val_accuracy: 0.4173\n",
      "Epoch 6/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 1.6888 - accuracy: 0.5651 - val_loss: 2.3983 - val_accuracy: 0.4536\n",
      "Epoch 7/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 1.4798 - accuracy: 0.6266 - val_loss: 2.2724 - val_accuracy: 0.4637\n",
      "Epoch 8/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 1.3629 - accuracy: 0.6740 - val_loss: 2.2229 - val_accuracy: 0.5020\n",
      "Epoch 9/36\n",
      "60/60 [==============================] - 125s 2s/step - loss: 1.1061 - accuracy: 0.7229 - val_loss: 2.2447 - val_accuracy: 0.5101\n",
      "Epoch 10/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.9363 - accuracy: 0.7526 - val_loss: 2.1547 - val_accuracy: 0.5101\n",
      "Epoch 11/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.8791 - accuracy: 0.7698 - val_loss: 2.1750 - val_accuracy: 0.5544\n",
      "Epoch 12/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.8188 - accuracy: 0.7823 - val_loss: 2.1819 - val_accuracy: 0.5302\n",
      "Epoch 13/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.6995 - accuracy: 0.8167 - val_loss: 2.1898 - val_accuracy: 0.5887\n",
      "Epoch 14/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.7132 - accuracy: 0.8234 - val_loss: 2.3959 - val_accuracy: 0.5262\n",
      "Epoch 15/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.5867 - accuracy: 0.8474 - val_loss: 2.3439 - val_accuracy: 0.5766\n",
      "Epoch 16/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.6409 - accuracy: 0.8510 - val_loss: 2.3758 - val_accuracy: 0.5484\n",
      "Epoch 17/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.5810 - accuracy: 0.8703 - val_loss: 2.6990 - val_accuracy: 0.5524\n",
      "Epoch 18/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.5398 - accuracy: 0.8760 - val_loss: 2.4980 - val_accuracy: 0.5645\n",
      "Epoch 19/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.4741 - accuracy: 0.8828 - val_loss: 2.5787 - val_accuracy: 0.5504\n",
      "Epoch 20/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.4840 - accuracy: 0.8911 - val_loss: 2.5613 - val_accuracy: 0.5565\n",
      "Epoch 21/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.4236 - accuracy: 0.8990 - val_loss: 2.4381 - val_accuracy: 0.5706\n",
      "Epoch 22/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3799 - accuracy: 0.9083 - val_loss: 2.5322 - val_accuracy: 0.5786\n",
      "Epoch 23/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3552 - accuracy: 0.9177 - val_loss: 2.6344 - val_accuracy: 0.5988\n",
      "Epoch 24/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.3411 - accuracy: 0.9250 - val_loss: 2.8966 - val_accuracy: 0.5464\n",
      "Epoch 25/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.4103 - accuracy: 0.9172 - val_loss: 2.6955 - val_accuracy: 0.5665\n",
      "Epoch 26/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3789 - accuracy: 0.9099 - val_loss: 2.9298 - val_accuracy: 0.5706\n",
      "Epoch 27/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.3431 - accuracy: 0.9203 - val_loss: 2.9421 - val_accuracy: 0.5524\n",
      "Epoch 28/36\n",
      "60/60 [==============================] - 126s 2s/step - loss: 0.3839 - accuracy: 0.9193 - val_loss: 2.7587 - val_accuracy: 0.5766\n",
      "Epoch 29/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.2869 - accuracy: 0.9385 - val_loss: 2.8098 - val_accuracy: 0.5645\n",
      "Epoch 30/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3028 - accuracy: 0.9375 - val_loss: 3.0078 - val_accuracy: 0.5524\n",
      "Epoch 31/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.4163 - accuracy: 0.9318 - val_loss: 3.2621 - val_accuracy: 0.5565\n",
      "Epoch 32/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3261 - accuracy: 0.9474 - val_loss: 3.1398 - val_accuracy: 0.5504\n",
      "Epoch 33/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3177 - accuracy: 0.9370 - val_loss: 2.8049 - val_accuracy: 0.5988\n",
      "Epoch 34/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.3044 - accuracy: 0.9406 - val_loss: 3.1123 - val_accuracy: 0.5565\n",
      "Epoch 35/36\n",
      "60/60 [==============================] - 123s 2s/step - loss: 0.2755 - accuracy: 0.9417 - val_loss: 3.1291 - val_accuracy: 0.5625\n",
      "Epoch 36/36\n",
      "60/60 [==============================] - 124s 2s/step - loss: 0.3452 - accuracy: 0.9328 - val_loss: 2.9847 - val_accuracy: 0.5706\n"
     ]
    }
   ],
   "source": [
    "plot_compare = classifier.fit_generator(training_set,\n",
    "                    steps_per_epoch=(60),\n",
    "                    epochs = 36,\n",
    "                    validation_data=val_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "broadband-active",
   "metadata": {},
   "source": [
    "The accuracy of the model is approximately 94.17% \n",
    "Using simple CNN model "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
